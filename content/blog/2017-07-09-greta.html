---
title: "Greta"
date: "2017-07-08T10:12:00+03:00"
tags: ["tensorflow", "bayes"]
categories: ["tutoriais", "r"]
banner: "img/banners/banner-greta.png"
author: ["Daniel"]
summary: "Greta é um pacote de modelagem estatística que permite que você defina seus modelos interativamente em R e depois os estime usando MCMC."
---



<p>Estou bem longe de ter experiência em modelagem bayesiana usando linguagens de programação probabilística como Stan ou BUGS, mas vi esse pacote chamado <a href="https://goldingn.github.io/greta/get_started.html"><code>greta</code></a> que me chamou a atenção.</p>
<p>O <code>greta</code> é um pacote feito totalmente em R, mas que usa o TensorFlow como backend para fazer os seus cálculos. Isso tudo por intermédio do <code>reticulate</code>. A vantagem de usar o TensorFlow como <em>backend</em> é a escalabilidade: o <code>greta</code> pode ser rápido até mesmo em bases de dados grandes e também pode ser acelerada usando clusters de CPU’s ou GPU’s.</p>
<p>O <code>greta</code> já está disponível no CRAN e pode ser instalado com:</p>
<pre class="r"><code>install.packages(&quot;greta&quot;)</code></pre>
<p>Vou mostrar um exemplo simples copiado da página de início do site do próprio <code>greta</code> e depois vou implementar um modelo que o Fernando implementou aqui no blog em um outro post sobre estimar um modelo heterocedástico no R.</p>
<section id="exemplo-simples" class="level1">
<h1>Exemplo simples</h1>
<p>Vamos implementar o modelo de regressão linear mais simples possível. Temos duas variáveis contínuas <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> e queremos estimar um modelo da forma:</p>
<p><span class="math display">\[y = a + b*x + \epsilon\]</span></p>
<p>em que <span class="math inline">\(\epsilon\)</span> possui distribuição normal com média zero e desvio padrão <span class="math inline">\(\sigma\)</span>. No greta isso pode ser feito da seguinte forma:</p>
<pre class="r"><code>library(greta)
# define as variáveis x e y
x &lt;- iris$Petal.Length
y &lt;- iris$Sepal.Length

# define a distribuição priori dos parâmetros
a = normal(0, 5)
b = normal(0, 3)
sd = lognormal(0, 3)

# define o modelo
mean &lt;- a + b * x
distribution(y) = normal(mean, sd)
m &lt;- model(a, b, sd)

# retira amostras usando mcmc
draws &lt;- mcmc(m, n_samples = 1000)</code></pre>
<p>Você pode fazer um gráfico para visualizar as estimativas dos parâmetros usando o <code>bayesplot</code>:</p>
<pre class="r"><code>bayesplot::mcmc_trace(draws, facet_args = list(ncol = 1))</code></pre>
<p><img src="/img/blog/greta/Rplot.png" /></p>
<p>Podemos obter as estimativas pontuais dos parâmetros pegando, por exemplo, a mediana dessa amostra do MCMC.</p>
<pre class="r"><code>apply(draws[[1]], 2, median)
##         a         b        sd 
## 4.2805710 0.4219092 0.3697692</code></pre>
<p>Esse resultado é muito similar ao que pode ser obtido por uma regressão linear simples:</p>
<pre class="r"><code>lm(y ~ x)
## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##      4.3066       0.4089</code></pre>
</section>
<section id="modelo-linear-heterocedastico" class="level1">
<h1>Modelo linear heterocedástico</h1>
<p><a href="http://curso-r.com/blog/2017/03/09/2017-02-21-regressao-heterocedastica/">Neste post</a> o Fernando simulou um banco de dados que é heterocedástico e depois ajustou um modelo deste tipo de diversas maneiras, vou acrescentar mais uma aqui, desta vez usando o <code>greta</code>.</p>
<p>Vou simular o banco de dados da mesma forma que o Fernando:</p>
<pre class="r"><code>library(ggplot2)

N &lt;- 1000

set.seed(11071995)
X &lt;- sample((N/100):(N*3), N)
Y &lt;- rnorm(N,X,4*sqrt(X))

qplot(X,Y) + 
  theme_bw(15) + 
  geom_point(color = &#39;darkorange&#39;)  </code></pre>
<p><img src="/blog/2017-07-09-greta_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>
X2 &lt;- sqrt(X)
dataset &lt;- data.frame(Y,X,X2)</code></pre>
<p>Agora o código em <code>greta</code> para ajustar esse modelo:</p>
<pre class="r"><code># definir os vetores
y &lt;- dataset$Y
x &lt;- dataset$X
x2 &lt;- dataset$X2

# definir prioris dos parâmetros
alpha &lt;- gamma(1, 1)
beta &lt;- normal(0, 10)

# definir ligações
mean &lt;- beta * x
sd &lt;- alpha * x2

# definir o modelo
distribution(y) = normal(mean, sd)
m &lt;- model(alpha, beta)

# ajustar
draws &lt;- mcmc(m, n_samples = 1000)</code></pre>
<p>Agora as estimativas pontuais:</p>
<pre class="r"><code>apply(draws[[1]], 2, median)
##    alpha     beta 
## 4.077689 1.002791</code></pre>
<p>Como esperado, chegamos em estimativas bem próximas do que foi simulado.</p>
<p>Por hoje é isso!! Abraços!</p>
</section>
