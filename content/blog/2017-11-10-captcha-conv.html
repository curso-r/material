---
title: "Quebrando Captchas - Parte V: Fazendo redes convolucionais na mão"
date: "2017-11-12T23:26:00+03:00"
tags: ["captcha"]
categories: ["análises", "r"]
banner: "img/banners/captcha_05.png"
author: ["Julio"]
summary: "Nesse post vou mostrar como ajustar redes neurais convolucionais na mão. Muita mão na massa envolvida, muitos captchas e muita diversão. Vamos juntos desmistificar a magia negra do deep learning..."
draft: false
---



<p>Voltando aos saudosos captchas. Demorei para fazer esse post pois estava esperando o lançamento do <a href="https://www.coursera.org/learn/convolutional-neural-networks">curso de redes neurais convolucionais do Andrew Ng</a>. O curso foi muito bom, valeu à pena! E, como prometido, vamos agora trabalhar com modelagem dos captchas.</p>
<section id="objetivo" class="level2">
<h2>Objetivo</h2>
<p>Nosso objetivo é aprender a aplicar a <strong>operação da convolução</strong> em imagens, replicando o modelo já ajustado dos captchas. O jeito que fazemos para ajustar o modelo ficará para um próximo post.</p>
<section id="pre-requisitos" class="level3">
<h3>Pré-requisitos</h3>
<p>Na nossa jornada, utilizaremos o pacote <code>decryptr</code> e teremos como o base o captcha da Receita Federal. Para baixar um captcha e plotar na sua tela, rode o código abaixo. Utilizaremos o caminho do arquivo em <code>arq</code> várias vezes no decorrer do post. Instale também o pacote <code>decryptrModels</code> para carregar o modelo ajustado do captcha da receita.</p>
<pre class="r"><code># devtools::install_github(&quot;decryptr/decryptr&quot;)
# devtools::install_github(&quot;decryptr/decryptrModels&quot;)
library(decryptr)
arq &lt;- captcha_download_rfb(dest = &quot;img&quot;)
arq %&gt;% 
  read_captcha() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-2-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>Também precisaremos do <a href="https://keras.rstudio.com/"><code>keras</code></a>, um pacote maravilhoso feito pela turma do <a href="https://rstudio.com">RStudio</a>, com contribuições do <a href="http://curso-r.com/author/daniel/">Daniel Falbel</a>. Não esqueça de fazer o <code>tensorflow</code> funcionar na sua máquina! <a href="http://curso-r.com/blog/2017/06/08/2017-06-08-keras-no-ubuntu/">Esse post</a> do <a href="http://curso-r.com/author/athos/">Athos Damiani</a> pode ajudar.</p>
<pre class="r"><code># install.packages(&quot;keras&quot;)
library(keras)</code></pre>
<p>Para os retoques finais nas imagens, vamos usar o pacote <code>magick</code>. Meu intuito inicial era usar a função <code>image_convolve()</code> desse pacote, mas infelizmente essa operação é limitada. Acabei usando apenas funções para juntar imagens e fazer gifs. Se quiser mais detalhes sobre o <code>magick</code>, veja o excelente post <a href="http://curso-r.com/blog/2017/06/01/2017-06-01-a-kind-of-magick/">A kind of magick</a>, feito pelo <a href="http://curso-r.com/author/william/">William Amorim</a>.</p>
<pre class="r"><code># install.packages(&quot;magick&quot;)
library(magick)
## Linking to ImageMagick 6.9.9.25
## Enabled features: cairo, fontconfig, freetype, fftw, lcms, pango, rsvg, webp
## Disabled features: ghostscript, x11</code></pre>
</section>
</section>
<section id="o-que-e-convolucao-afinal" class="level2">
<h2>O que é convolução, afinal?</h2>
<p><img src="/img/blog/captcha-conv/vivalaconv.jpg" width="50%" style="display: block; margin: auto;" /></p>
<p>Convolução é uma técnica usada há muito tempo na área de <em>visão computacional</em> para aplicar filtros em imagens e detectar padrões. Basicamente, o que ela faz é calcular um novo valor para um pixel da imagem com base nos pixels da vizinhança. Por exemplo, você pode fazer com que o pixel <span class="math inline">\((i,j)\)</span> da sua imagem seja atualizado pela soma ponderada dos valores dos pixels na vizinhança.</p>
<blockquote>
<p>Se você não está entendendo nada, Veja o vídeo abaixo para entender o que são pixels. No nosso caso, teremos uma matriz com valores entre zero e um, sendo zero = preto e um = branco.</p>
</blockquote>
<iframe width="400" height="225" src="https://www.youtube.com/embed/m8c1CAT2zEI" frameborder="0" allowfullscreen>
</iframe>
<p>Uma forma esperta de fazer essa soma ponderada é criando uma matriz de pesos: dessa forma, você não precisa ficar procurando os pontos da vizinhança. Para cada ponto <span class="math inline">\((i,j)\)</span>, você pega o subset da matriz de vizinhança, multiplica pontualmente pela matriz de pesos e soma todos os valores. Isso é <em>exatamente</em> o que a convolução faz.</p>
<p>Daqui em diante, chamaremos essa matriz de pesos de <strong>kernel</strong>. Considere esse exemplo 3x3:</p>
<pre class="r"><code>kern_horizontal &lt;- rbind(c(-1,-1,-1),
                         c( 0, 0, 0),
                         c( 1, 1, 1))
kern_horizontal
##      [,1] [,2] [,3]
## [1,]   -1   -1   -1
## [2,]    0    0    0
## [3,]    1    1    1</code></pre>
<p>E considere essa imagem super complexa:</p>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-7-1.png" width="30%" style="display: block; margin: auto;" /></p>
<p>Na prática, essa imagem é isso aqui (tirei algumas linhas e colunas):</p>
<pre class="r"><code>emoji &lt;- load_image(&quot;../../static/img/blog/captcha-conv/emoji3.png&quot;)[,,1] 
round(emoji, 1)[1:10, 1:12]
##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
##  [1,]    1    1    1  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0   1.0
##  [2,]    1    1    1  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0   1.0
##  [3,]    1    1    1  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0   1.0
##  [4,]    1    1    1  1.0  1.0  1.0  1.0  1.0  0.8   0.7   0.7   0.7
##  [5,]    1    1    1  1.0  1.0  1.0  0.9  0.6  0.8   1.0   1.0   1.0
##  [6,]    1    1    1  1.0  1.0  0.8  0.7  1.0  1.0   1.0   1.0   1.0
##  [7,]    1    1    1  1.0  0.9  0.7  1.0  1.0  1.0   1.0   1.0   1.0
##  [8,]    1    1    1  1.0  0.6  1.0  1.0  1.0  1.0   1.0   1.0   1.0
##  [9,]    1    1    1  0.8  0.8  1.0  1.0  0.9  0.9   1.0   1.0   1.0
## [10,]    1    1    1  0.7  1.0  1.0  0.7  0.4  0.2   0.7   0.9   1.0</code></pre>
<p>Tome por exemplo o ponto <span class="math inline">\((i,j) = (12,16)\)</span>. A vizinhança 3x3 em torno desse ponto é dada por</p>
<pre class="r"><code>emoji[12 + (-1):1, 16 + (-1):1]
##           [,1]      [,2]      [,3]
## [1,] 0.9843137 0.5294118 0.7921569
## [2,] 0.9725490 0.9882353 1.0000000
## [3,] 0.9843137 1.0000000 0.9960784</code></pre>
<p>A operação de convolução é feita da seguinte forma:</p>
<pre class="r"><code>sum(emoji[12 + (-1):1, 16 + (-1):1] * kern_horizontal)
## [1] 0.6745098</code></pre>
<p>Pronto, esse é o valor a ser colocado no ponto <span class="math inline">\((i,j)\)</span>. Fazemos isso para todos os outros pontos. Algumas dúvidas que podem rolar nesse ponto:</p>
<p><strong>Q</strong>: Mas os números não devem variar de 0 a 1?</p>
<p><strong>R</strong>: Não! Para visualizar a imagem, você poderia normalizar essas quantidades (por exemplo, dividindo pelo máximo). Mas quem disse que o resultado da sua operação precisa ser visualizável? O resultado pode até ser negativo. Sem problemas.</p>
<blockquote>
<p>Para visualização, por padrão os valores menores que zero são substituídos por zero (preto) e valores maiores que um são substituídos por um (branco).</p>
</blockquote>
<p><strong>Q</strong>: Mas e no canto da imagem, o que fazemos?</p>
<p><strong>R</strong>: Nos cantos, você tem duas opções: 1) considerar apenas os pixels <em>válidos</em>, ou seja, pixels em que você consegue encaixar a matriz <code>kernel</code> inteira, resultando numa matriz de tamanho menor; ou 2) criar uma borda na imagem, preenchendo com zeros, para que toda a imagem fique com pixels válidos. Por isso que o <code>keras</code> disponibiliza as opções <em>valid</em> (apenas os válidos) e <em>same</em> (mantém a mesma dimensão).</p>
<p><strong>Q</strong>: E se a imagem for colorida?</p>
<p><strong>R</strong>: Boa pergunta! Se a imagem for colorida, você pode considerar um <code>kernel</code> diferente para cada cor, e depois você soma todos os valores. Mais pra frente, chamaremos as cores de <em>canais</em>, pois teremos muito mais do que 3 kernels.</p>
<p>Com base nisso, montei um algoritmo que faz a conta para todos os pixels, já criando uma borda na imagem:</p>
<pre class="r"><code>convolve &lt;- function(img, kern) {
  # monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2,
  # de tamanho, arredondando para baixo
  pad &lt;- floor(dim(kern)[1] / 2)
  img_pad &lt;- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad)
  img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] &lt;- img[,,1]
  # aplica a convolução nos pontos da imagem
  for (i in seq_len(nrow(img))) {
    for (j in seq_len(ncol(img))) {
      img[i, j, 1] &lt;- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern)
    }
  }
  img[,,2] &lt;- img[,,3] &lt;- img[,,1]
  img
}</code></pre>
<p>(desculpe aos amigos por usar <code>for</code>. Shame on me…)</p>
<p>Voltando para nossa imagem agora. No nosso caso, o resultado fica assim:</p>
<pre class="r"><code>&quot;../../static/img/blog/captcha-conv/emoji3.png&quot; %&gt;% 
  load_image() %&gt;% 
  convolve(kern_horizontal) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-12-1.png" width="30%" style="display: block; margin: auto;" /></p>
<p>Ficou um pouco assustador, não? Essa matriz não foi escolhida por acaso. Ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada <code>-1</code>s e a última é formada por <code>1</code>s, a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (<code>grande * 1 + pequeno * (-1)</code>). A parte destacada da imagem acabou sendo os olhos (pois temos maior concentração de pixels pretos ali), além das extremidades superior e inferior do rosto.</p>
<p>Com esse kernel aqui (vertical), a parte destacada do rosto são as extremidades dos lados:</p>
<pre class="r"><code>kern_vertical &lt;- rbind(c(-1, 0, 1),
                       c(-1, 0, 1),
                       c(-1, 0, 1))
kern_vertical
##      [,1] [,2] [,3]
## [1,]   -1    0    1
## [2,]   -1    0    1
## [3,]   -1    0    1

&quot;../../static/img/blog/captcha-conv/emoji3.png&quot; %&gt;% 
  load_image() %&gt;% 
  convolve(kern_vertical) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-13-1.png" width="30%" style="display: block; margin: auto;" /></p>
<p><hline /></p>
</section>
<section id="aplicando-nos-captchas" class="level2">
<h2>Aplicando nos captchas</h2>
<p>Não tem segredo! Basta reaplicar o que já vimos. Vou apenas introduzir uma nova função chamada <code>add_bias()</code>, que simplesmente adiciona uma constante numérica para a matriz. Isso pode auxiliar na visualização, pois controlamos melhor os valores que ficam dentro do intervalo <code>[0,1]</code>. Lá na frente você entenderá o porquê do “bias”.</p>
<pre class="r"><code>add_bias &lt;- function (x, b) x + b</code></pre>
<p>Esse é o resultado de adicionar o kernel vertical e bias de <code>0.8</code>.</p>
<pre class="r"><code>arq %&gt;% 
  load_image() %&gt;% 
  convolve(kern_vertical) %&gt;% 
  add_bias(.8) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-15-1.png" width="345.6" style="display: block; margin: auto;" /></p>
<p>Agora o kernel na horizontal. Note que identificamos padrões das linhas horizontais que tentam atrapalhar a visão das letras.</p>
<pre class="r"><code>arq %&gt;% 
  load_image() %&gt;% 
  convolve(kern_horizontal) %&gt;% 
  add_bias(.8) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-16-1.png" width="345.6" style="display: block; margin: auto;" /></p>
<p>Colocando um após o outro, temos um resultado bem esquisito:</p>
<pre class="r"><code>arq %&gt;% 
  load_image() %&gt;% 
  convolve(kern_horizontal) %&gt;% 
  convolve(kern_vertical) %&gt;% 
  add_bias(.7) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-17-1.png" width="345.6" style="display: block; margin: auto;" /></p>
<p>Também vou introduzir uma função chamada <code>relu()</code> aqui. <strong>ReLu</strong> significa <em>Restricted Linear Unit</em> e é uma função bem simples que zera tudo aquilo que é negativo e mantém tudo aquilo que é positivo. Assim, temos:</p>
<pre class="r"><code>relu &lt;- function(x) (x + abs(x)) / 2
relu(-1)
## [1] 0
relu( 3)
## [1] 3</code></pre>
<p>Para visualização, essa função não serve para muita coisa, pois já fazemos a substituição de valores negativos por zero. No entanto, podemos fazer combos com a aplicação de várias convoluções. O resultado dos combos não seria possível somente com somas e multiplicações. Na prática, o que estou afirmando é que com a aplicação de convoluções, bias e ReLu, podemos montar operações <strong>não lineares</strong> para extrair componentes da imagem.</p>
<p>Olhe o exemplo abaixo. Parece que consegui identificar bem as coisas que são inúteis na imagem. Isso pode ser útil… ou não.</p>
<pre class="r"><code>arq %&gt;% 
  load_image() %&gt;% 
  # primeira convolucao
  convolve(kern_horizontal) %&gt;%
  add_bias(-.25) %&gt;% 
  relu() %&gt;% 
  # segunda convolucao
  convolve(kern_vertical) %&gt;% 
  add_bias(.1) %&gt;% 
  image_read() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-19-1.png" width="345.6" style="display: block; margin: auto;" /></p>
<p>Isso tudo nos leva a pensar: será que eu consigo pensar em kernels que me ajudem a identificar as letras de uma forma razoável?</p>
<p><hline /></p>
</section>
<section id="e-se-pudermos-usar-kernels-treinados" class="level2">
<h2>E se pudermos usar kernels treinados?</h2>
<p>A revolução da convolução aparece quando conseguimos obter kernels úteis por métodos estatísticos. Podemos pensar na matriz abaixo</p>
<p><span class="math display">\[
W = \left[\begin{array}{ccccc}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} &amp; w_{15} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} &amp; w_{25} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34} &amp; w_{35} \\
w_{41} &amp; w_{42} &amp; w_{43} &amp; w_{44} &amp; w_{45} \\
w_{51} &amp; w_{52} &amp; w_{53} &amp; w_{54} &amp; w_{55}
\end{array}\right]
\]</span></p>
<p>e tentar encontrar os valores de <span class="math inline">\(W\)</span> que minimizem alguma função de interesse. Podemos pensar que esses são os <span class="math inline">\(\beta\)</span>’s de uma regressão logística, e queremos encontrar os valores que minimizam uma <em>Loss</em> ou maximizam uma <em>verossimilhança</em>. Para ver mais sobre isso, recomendo o excelente post do Athos sobre <a href="http://curso-r.com/blog/2017/07/29/2017-07-29-segundo-menor-dl/">a menor deep learning do mundo</a>. Nós também podemos fazer vários <span class="math inline">\(W\)</span> como esse, sendo que cada um extrai alguma coisa de importante da imagem.</p>
<p>Nosso super modelo de magia negra nada mais é do que isso: a aplicação consecutiva de <code>convolve()</code>, <code>add_bias()</code> e <code>relu()</code>, mas com pesos escolhidos a dedo (ou por um moedor de carne super-poderoso como o <code>keras</code>).</p>
<p>Agora podemos ver nosso modelo atual da Receita Federal:</p>
<pre class="r"><code>m &lt;- decryptrModels::read_model(&quot;rfb&quot;)
m$model</code></pre>
<pre><code>Model
____________________________________________________________________________________________________
Layer (type)                                 Output Shape                            Param #        
====================================================================================================
conv2d_4 (Conv2D)                            (None, 50, 180, 12)                     312            
____________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)               (None, 25, 90, 12)                      0              
____________________________________________________________________________________________________
conv2d_5 (Conv2D)                            (None, 25, 90, 48)                      14448          
____________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)               (None, 12, 45, 48)                      0              
____________________________________________________________________________________________________
conv2d_6 (Conv2D)                            (None, 12, 45, 96)                      115296         
____________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)               (None, 6, 22, 96)                       0              
____________________________________________________________________________________________________
flatten_2 (Flatten)                          (None, 12672)                           0              
____________________________________________________________________________________________________
dense_3 (Dense)                              (None, 32)                              405536         
____________________________________________________________________________________________________
dropout_2 (Dropout)                          (None, 32)                              0              
____________________________________________________________________________________________________
dense_4 (Dense)                              (None, 210)                             6930           
____________________________________________________________________________________________________
reshape_2 (Reshape)                          (None, 6, 35)                           0              
____________________________________________________________________________________________________
activation_2 (Activation)                    (None, 6, 35)                           0              
====================================================================================================
Total params: 542,522
Trainable params: 542,522
Non-trainable params: 0
____________________________________________________________________________________________________</code></pre>
<p>O modelo aplica convolução 3 vezes consecutivas e faz algumas contas que não entendemos. Explico agora:</p>
<ol type="1">
<li><code>conv2d_</code>: são as convoluções. As aplicações de <code>add_bias()</code> e <code>relu()</code> estão escondidas aí dentro.</li>
<li><code>max_pooling2d_</code>: serve para simplificar a imagem. Isso ajuda a fazer computações mais rápido e ajuda a pegar mais relações entre partes da imagem, sem precisar mudar o tamanho dos kernels.</li>
<li><code>dropout_</code>: é utilizado para regularização. Serve para evitar que seu modelo quebre apenas o captcha que você tem na base, e não novos captchas que chegam. Na prática, o <em>dropout</em> joga fora uma parte dos <span class="math inline">\(W\)</span> obtidos. Se você consegue prever coisas bem sem esses <span class="math inline">\(W\)</span>, isso significa que eles não são tão úteis assim.</li>
<li><code>flatten_</code> e <code>reshape_</code>: não fazem nada demais, só reorganizam os parâmetros de matriz para um vetor ou de vetor para matriz. Isso é útil pois i) depois de aplicar os kernels, nós misturamos todos os parâmetros resultantes e ii) no final, precisamos prever 6 letras, então precisamos deixar as probabilidades numa matriz, <a href="http://curso-r.com/blog/2017/07/31/2017-06-29-captcha-dados/">como vimos no post anterior sobre captchas</a>.</li>
<li><code>dense_</code>: são camadas de redes neurais comuns como as do <a href="http://curso-r.com/blog/2017/07/29/2017-07-29-segundo-menor-dl/">post do Athos</a>.</li>
</ol>
<p><strong>NÃO ME ABANDONE AQUI!!!</strong> Se você não estiver entendendo direito, saiba apenas que a execução de um modelo de deep learning envolve somente</p>
<ol type="1">
<li>Pegar o input (imagem).</li>
<li>Multiplicar (convoluir) por alguns pesos <span class="math inline">\(W\)</span>.</li>
<li>Adicionar um viés (ou bias, ou intercepto) <span class="math inline">\(b\)</span>.</li>
<li>Aplicar uma função não linear, por exemplo ReLu.</li>
<li>Voltar para 2 várias vezes (o deep vem daí).</li>
<li>Pegar os pesos finais e normalizar (usando, por exemplo, <em>softmax</em>) para obter probabilidades dos resultados.</li>
</ol>
<p>No nosso caso, repetimos o passo 2 três vezes, aplicando três convoluções seguidas.</p>
<section id="primeira-convolucao" class="level3">
<h3>Primeira convolução</h3>
<p>Para obter os valores de kernels ajustados pelo modelo, podemos usar a função <code>get_weights()</code> do <code>keras</code>. Nessa primeira parte, utilizamos 12 kernels 5x5.</p>
<pre class="r"><code>w &lt;- keras::get_weights(m$model$layers[[1]])[[1]]
w_list &lt;- purrr::map(seq_len(dim(w)[4]), ~w[,,1,.x])
bias &lt;- keras::get_weights(m$model$layers[[1]])[[2]]
w_list[[1]]</code></pre>
<pre><code>            [,1]        [,2]        [,3]        [,4]        [,5]
[1,] -0.00889198  0.04569587  0.11906113  0.08591988 -0.09028889
[2,] -0.05898214  0.20692091 -0.13479255 -0.15641896 -0.10511240
[3,]  0.02517573 -0.63352644 -3.81658459 -4.39883375 -1.05918467
[4,] -0.22003661 -1.80763698 -3.13373542 -1.73096466 -0.01640752
[5,] -0.02915078 -0.11879896 -0.07475707  0.06014036  0.15733875</code></pre>
<p>Os doze valores de <code>bias</code> estimados pelo modelo (um para cada matriz) são dados por</p>
<pre class="r"><code>round(bias, 3)</code></pre>
<pre><code>[1]  0.150  0.013  0.181 -0.275  0.179  0.040 -0.128 -0.036  0.030  0.042  0.201  0.043</code></pre>
<p>Para cada um dos doze kernels, calculamos uma matriz convoluída. Esses os resultados que o modelo entende serem úteis para prever o captcha.</p>
<p>O código abaixo aplica <code>convolve()</code>, <code>add_bias()</code> e <code>relu()</code> para todos os kernels. Para isso usamos o <code>purrr</code>. Se você não entende <code>purrr</code>, leia <a href="http://ctlente.com/pt/purrr-magic/">este maravilhoso post do Caio Lente</a>.</p>
<pre class="r"><code>conv1 &lt;- purrr::map2(w_list, bias, ~{
  arq %&gt;% 
    load_image() %&gt;% 
    convolve(.x) %&gt;% 
    add_bias(.y) %&gt;% 
    relu()
})</code></pre>
<p>E como será que ficam essas imagens? Abaixo, temos o resultado da aplicação dos doze kernels. A maioria parece estar extraindo partes das letras. A sétima (posição <code>(2,3)</code>) parece estar pegando o ruído e a quarta parece guardar a imagem original.</p>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-24-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>O gif animado abaixo mostra a aplicação do oitavo kernel da nossa lista. Com esse kernel dá pra pegar bem o padrão das letras, não é?</p>
<p><img src="/img/blog/captcha-conv/captcha_conv.gif" /></p>
<p>No próximo nível, vamos convoluir mais 48 kernels. Essa operação será feita com todos os doze filtros atuais, ou seja, é uma contaiada que não acaba mais. Para simplificar as contas e para permitir a obtenção de padrões diferentes, faz sentido simplificar a imagem. Para isso, usamos o <em>max pooling</em>.</p>
<section id="aplicando-max-pooling" class="level4">
<h4>Aplicando max pooling</h4>
<p>O max pooling simplesmente pega o pixel de maior valor dentro de uma janela. No caso, estamos usando uma janela 2x2 e aplicamos ela igualzinho convolução, só que ao invés de pegar a soma ponderada dos pixels, pegamos o pixel máximo. Outra diferença é que ao invés de andar o pixel de 1 em 1, andamos de 2 em 2. Assim cada janelinha é considerada apenas uma vez (esse é o conceito de <em>strides</em>, que não vou discutir aqui).</p>
<p>Montei esse algoritmo que faz max pooling:</p>
<pre class="r"><code>max_pool &lt;- function(img) {
  # monta a matriz com metade da resolução
  x_new &lt;- matrix(0.0, nrow = floor(nrow(img) / 2), ncol = floor(ncol(img) / 2))
  # adiciona uma bordinha para o caso da matriz ter um número ímpar de pixels
  # por exemplo, se ela é 51x181, daria bug se não adicionar a bordinha
  img &lt;- cbind(rbind(img[,,1], 0), 0)
  # percorre a matrix pegando o máximo das janelinhas
  for (i in 1:nrow(x_new)) {
    for (j in 1:ncol(x_new)) {
      x_new[i, j] &lt;- max(img[i * 2 - 1 + 0:1, j * 2 - 1 + 0:1])
    }
  }
  array(x_new, c(dim(x_new), 3))
}</code></pre>
<p>A aplicação da primeira convolução com max pooling é feita igual anteriormente:</p>
<pre class="r"><code>result_conv1 &lt;- purrr::map2(w_list, bias, ~{
  arq %&gt;% 
    load_image() %&gt;% 
    convolve(.x) %&gt;% 
    add_bias(.y) %&gt;%
    relu() %&gt;% 
    max_pool()
})</code></pre>
<p>No final, temos essas imagens com resolução <code>25x90</code> (as originais são <code>50x180</code>).</p>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-27-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Ficou bem parecido com o anterior!</p>
<p>Ao final da convolução, é como se tivéssemos uma nova imagem, menor e alterada, mas com 12 cores. Como não faz muito sentido pensar em 12 cores primárias, vamos chamá-las de canais.</p>
<p><hline /></p>
</section>
</section>
<section id="segunda-convolucao" class="level3">
<h3>Segunda convolução</h3>
<p>Os parâmetros da segunda convolução são obtidos novamente pelo <code>keras</code>. Sugiro que você dê uma olhada nesses índices para entender o que exatamente estamos pegando.</p>
<pre class="r"><code>w2 &lt;- keras::get_weights(m$model$layers[[3]])[[1]]
bias2 &lt;- keras::get_weights(m$model$layers[[3]])[[2]]

dim(w2)</code></pre>
<pre><code>[1]  5  5 12 48</code></pre>
<p>Agora temos <code>12 * 48</code> kernels 5x5 a serem aplicados. Precisamos seguir essas operações:</p>
<ol type="1">
<li>Para cada uma das 48 matrizes:
<ol type="1">
<li>Faça a convolução das 12 matrizes obtidos na convolução anterior pelos 12 kernels atuais e <strong>some</strong> os valores obtidos.</li>
<li>Adicione o bias.</li>
<li>Faça a ativação com ReLu.</li>
<li>Aplique o max pooling.</li>
</ol></li>
</ol>
<p>Logo, temos 2 laços. O código para fazer isso fica assim:</p>
<pre class="r"><code>result_conv2 &lt;- purrr::map(1:dim(w2)[4], ~{
  kern &lt;- w2[,,,.x] %&gt;% 
    plyr::alply(3, identity) %&gt;% 
    purrr::map(as.matrix)
  actual_bias &lt;- bias2[[.x]]
  purrr::map2(result_conv1, kern, convolve) %&gt;% 
    purrr::reduce(magrittr::add) %&gt;% 
    add_bias(actual_bias) %&gt;%
    relu() %&gt;% 
    max_pool()
})</code></pre>
<p>Plotamos os 48 resultados abaixo. Alguns resultados foram completamente zerados (eles devem ser úteis em outros captchas mais esquisitos), enquanto os demais pegam pedaços da imagem anterior que mal lembram o captcha original. A imagem da posição <code>(4,1)</code> é uma das únicas que mostra o captcha claramente. Isso mostra uma coisa comum do deep learning: quanto mais profundo vamos, menos entendemos o que de fato o modelo está fazendo. Recomendo fortemente a leitura <a href="https://distill.pub/2017/feature-visualization/">desse blog do distill</a>, que discute o assunto detalhadamente</p>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-30-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Agora temos 48 canais de uma imagem com dimensões <code>12x45</code>. Vamos em frente.</p>
</section>
<section id="terceira-convolucao" class="level3">
<h3>Terceira convolução</h3>
<p>A terceira convolução é feita de forma idêntica à segunda. A única diferença é que teremos no final 96 canais, pois estamos ajustando essa quantidade de kernels para cada canal.</p>
<pre class="r"><code>w3 &lt;- keras::get_weights(m$model$layers[[5]])[[1]]
bias3 &lt;- keras::get_weights(m$model$layers[[5]])[[2]]

dim(w3)</code></pre>
<pre><code>[1]  5  5 48 96</code></pre>
<p>Revisando o algoritmo:</p>
<pre class="r"><code>result_conv3 &lt;- purrr::map(1:dim(w3)[4], ~{
  kern &lt;- w3[,,,.x] %&gt;% 
    plyr::alply(3, identity) %&gt;% 
    purrr::map(as.matrix)
  actual_bias &lt;- bias3[[.x]]
  purrr::map2(result_conv2, kern, convolve) %&gt;% 
    purrr::reduce(magrittr::add) %&gt;% 
    add_bias(actual_bias) %&gt;%
    relu() %&gt;% 
    max_pool()
})</code></pre>
<p>Plotando os resultados, temos</p>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-33-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>No final, ficamos com 96 imagens com resolução <code>6x22</code> cada. Várias imagens ficaram zeradas e as que não ficaram parecem apenas feixes de luz no meio do breu. Pode ser que a posição dessas luzes tenha a ver com a posição de pedaços importantes do captcha original, que por sua vez seriam importantes para determinar o valor do captcha.</p>
<section id="verificando-se-funcionou-mesmo" class="level4">
<h4>Verificando se funcionou mesmo</h4>
<p>Quando eu montei o post, não estava 100% seguro das contas que estava fazendo. Pode ser que tenha alguma coisa diferente dentro do <code>keras</code>, que é um canhão que usa <code>tensorflow</code> por trás, fazendo alguma otimização esquisita. Por isso, também aprendi a plotar os resultados parciais do modelo quebrador de captchas diretamente do <code>keras</code>.</p>
<p>Podemos montar um modelo <em>parcial</em> do <code>keras</code> escolhendo qual o <em>layer</em> final do modelo.</p>
<pre class="r"><code>m2 &lt;- keras::keras_model(
  inputs = m$model$input,
  outputs = keras::get_layer(m$model, &quot;max_pooling2d_6&quot;)$output
)
m2</code></pre>
<pre><code>Model
____________________________________________________________________________________________________
Layer (type)                                 Output Shape                            Param #        
====================================================================================================
conv2d_4_input (InputLayer)                  (None, 50, 180, 1)                      0              
____________________________________________________________________________________________________
conv2d_4 (Conv2D)                            (None, 50, 180, 12)                     312            
____________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)               (None, 25, 90, 12)                      0              
____________________________________________________________________________________________________
conv2d_5 (Conv2D)                            (None, 25, 90, 48)                      14448          
____________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)               (None, 12, 45, 48)                      0              
____________________________________________________________________________________________________
conv2d_6 (Conv2D)                            (None, 12, 45, 96)                      115296         
____________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)               (None, 6, 22, 96)                       0              
====================================================================================================
Total params: 130,056
Trainable params: 130,056
Non-trainable params: 0
____________________________________________________________________________________________________</code></pre>
<p>Esse modelo é idêntico ao inicial, mas acaba no último max pooling. Para obter as imagens, utilizamos a função <code>predict</code> a partir da base de dados <code>X</code> montada com o <code>arq</code>, utilizando a função <code>prepare</code> do <code>decryptr</code>:</p>
<pre class="r"><code>X &lt;- prepare(read_captcha(arq))$x
res &lt;- predict(m2, X)

dim(res)</code></pre>
<pre><code>[1]  1  6 22 96</code></pre>
<p>O resultado pode ser plotado da seguinte forma:</p>
<pre class="r"><code>par(mfrow = c(12, 8), mar = c(.1,.1,.1,.1))
purrr::walk(seq_len(dim(res)[4]), ~{
  array(res[,,,.x], c(dim(res)[2:3], 3)) %&gt;% 
  image_read() %&gt;% 
  plot()
})</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-36-1.png" width="864" style="display: block; margin: auto;" /></p>
<p>Ufa, ficou igualzinho!</p>
<p>Apenas um check final: quero ver se os pesos obtidos são todos iguais. Para isso, ordeno todos os pesos obtidos diretamente pelo <code>keras</code> ou aplicando as minhas funções feitas no braço:</p>
<pre class="r"><code>w_calculado &lt;- unlist(purrr::map(result_conv3, ~.x[,,1]))
all.equal(sort(res), sort(w_calculado), tolerance = 1e-6)</code></pre>
<pre><code>[1] TRUE</code></pre>
<p>UHUL!</p>
</section>
<section id="visualizando-na-imagem-original" class="level4">
<h4>Visualizando na imagem original</h4>
<p>Aqui fiz um esforço para tentar entender de qual parte da imagem original esses resultados estão pegando informações. Para isso, re-escalei essas imagens de resolução mais baixa na última convolução para o tamanho original do captcha (<code>50x180</code>) e depois multipliquei os valores das matrizes pelos valores da imagem original.</p>
<p>O resultado foi esse gif. Cada imagem é um dos canais obtidos.</p>
<p><img src="/img/blog/captcha-conv/captcha_conv_final.gif" /></p>
<p>Parece que os filtros são capazes de pegar as curvas que as letras fazem no captcha. Mas não tenho opinião formada sobre isso. Digam aí nos comentários o que vocês acham!</p>
</section>
</section>
</section>
<section id="passos-finais" class="level2">
<h2>Passos finais</h2>
<p>Para acabar a predição do captcha, nós pegamos os resultados das imagens anteriores e juntamos todos os pixels num vetorzão que junta tudo. Em estatistiquês, esse vetor nada mais é do que uma linha de um <code>data.frame</code>, que podemos usar numa regressão logística, por exemplo. Ou seja, essas convolucionais funcionam como um grande gerador automático de features importantes para prever os resultados do captcha. A vantagem é que essas features são obtidas de forma automática e são otimizadas dentro do processo de estimação. Por essas e outras que deep learning é realmente sensacional!</p>
<p>Como já estamos no framework do <code>keras</code>, acabamos fazendo tudo lá dentro. Após jogar tudo no vetorzão, aplicamos mais dois layers de redes neurais comuns, que funcionam como a regressão logística. O único detalhe sensível é que, como estamos prevendo 6 letras ao mesmo tempo, precisamos novamente transformar esse vetor em uma matriz <code>35x6</code>, sendo <code>35</code> o total de letras possíveis por posição e <code>6</code> a quantidade de posições.</p>
<p>Abaixo, montei uma tabelinha com as probabilidades de cada letra nas posições correspondentes. Substituí valores muito pequenos por <code>.</code> para ver melhor.</p>
<pre class="r"><code>res2 &lt;- keras::predict_proba(m$model, X)
probabilidades &lt;- res2[1,,] %&gt;% 
  tibble::as_tibble() %&gt;% 
  purrr::set_names(m$labs) %&gt;% 
  tidyr::gather(letra, prob) %&gt;% 
  dplyr::group_by(letra) %&gt;% 
  dplyr::mutate(pos = 1:n()) %&gt;% 
  dplyr::ungroup() %&gt;% 
  dplyr::mutate(prob = dplyr::if_else(prob &lt; 5e-5, &quot;.&quot;, as.character(round(prob, 6))) ) %&gt;% 
  tidyr::spread(pos, prob, sep = &quot;&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">letra</th>
<th style="text-align: left;">pos1</th>
<th style="text-align: left;">pos2</th>
<th style="text-align: left;">pos3</th>
<th style="text-align: left;">pos4</th>
<th style="text-align: left;">pos5</th>
<th style="text-align: left;">pos6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.999999</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.999987</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.000317</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">a</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">c</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">d</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">e</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">f</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">g</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.999949</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.001286</td>
</tr>
<tr class="odd">
<td style="text-align: left;">h</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">i</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">j</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">k</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">l</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">m</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">n</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">o</td>
<td style="text-align: left;">0.999887</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">p</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">q</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.998395</td>
</tr>
<tr class="odd">
<td style="text-align: left;">r</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">s</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">t</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">u</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">v</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">0.999997</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">w</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">x</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="even">
<td style="text-align: left;">y</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">z</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">.</td>
</tr>
</tbody>
</table>
<p>Ficamos então com “o” na primeira posição, “g” na segunda posição, “7” na terceira posição, “v” na quarta posição, “5” na quinta posição e “q” na sexta posição. Ou seja, “og7v5q”.</p>
<p>Vamos ver a imagem novamente:</p>
<pre class="r"><code>arq %&gt;% 
  read_captcha() %&gt;% 
  plot()</code></pre>
<p><img src="/blog/2017-11-10-captcha-conv_files/figure-html/unnamed-chunk-41-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Parece que funcionou!</p>
</section>
<section id="wrap-up" class="level2">
<h2>Wrap-up</h2>
<p>Essa jornada foi longa, mas acho que aprendemos bastante coisa. Resumindo:</p>
<ul>
<li>Convoluções são somas ponderadas dos valores da vizinhança de um pixel. Esses pesos são dados por uma matriz chamada kernel.</li>
<li>Aplicar redes neurais convolucionais consiste em i) aplicar convolução; ii) adicionar um bias; iii) aplicar uma função não linear (geralmente ReLu).</li>
<li><em>max pooling</em> serve para simplificar a resolução da imagem.</li>
<li>Na prática, aplicamos vários kernels. O número de kernels de uma convolucional igual ao número de canais da operação anterior (input), multiplicado pelo número de canais que queremos de output.</li>
<li>Para a convolução inicial, os canais são as cores: partimos de 1 canal se a imagem for preto e branco ou 3 canais se for colorida.</li>
<li>No nosso caso, aplicamos três convolucionais com kernels 5x5, sendo <code>1*12</code> no primeiro nível, <code>12*48</code> no segundo nível e <code>48*96</code> no terceiro nível.</li>
<li>Depois, pegamos as imagens resultantes e aplicamos o <code>flatten</code>, para trabalhar com esses números como se fossem a matriz <code>X</code> de uma regressão logística usual.</li>
<li>Como vimos, é possível implementar todas essas operações na mão sem muita dificuldade.</li>
</ul>
<p>Conseguimos! Mas resta uma dúvida…</p>
<p>Como é que, de fato, conseguimos esses valores mágicos de <span class="math inline">\(W\)</span>? Na próxima vez provavelmente resolverei esse problema, mostrando como se faz o back-propagation em um modelo de deep learning.</p>
<p>É isso. Happy coding :)</p>
</section>
